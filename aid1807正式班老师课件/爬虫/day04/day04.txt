Day03笔记
1、requests模块
  1、get()参数
    1、查询参数 ：params={字典}
    2、代理 ： proxies={字典}
      1、普通代理 : {"协议":"协议://IP:端口}"
      2、私密代理
        {"协议":"协议://用户名:密码@IP:端口"}
    3、Web客户端验证 ：auth=(元组)
      auth = ("tarenacode","code_2013")
    4、SSL证书认证(verify=True | False)
    5、timeout=3
      requests.get(url,headers=headers,timeout=3)
  2、post()
    1、data=字典  字典中是Form表单数据
  3、响应对象res属性
    1、text ：字符串
    2、content ：字节流
    3、encoding ：res.encoding="utf-8"
    4、status_code ：HTTP响应码
    5、url  ：返回实际数据的URL地址
2、Cookie模拟登陆
  1、登录成功1次,抓取到headers里的cookie
  2、headers={"User-Agent":"",
              "cookie":"dkfjdkljkjlefjlj......."}
3、Handler处理器(urllib.request)
  1、使用流程
    1、创建Handler对象
      phandler = urllib.request.ProxyHandler({字典})
    2、创建opener对象
      opener = urllib.request.build_opener(phandler)
    3、发请求获响应
      req = urllib.request.Request(url,headers=headers)
      res = opener.open(req)
  2、分类
    1、ProxyHandler({普通代理字典})
    2、ProxyBasicAuthHandler(密码管理器对象)
    3、HTTPBasicAuthHandler(密码管理器对象)
    4、流程
      1、密码管理器对象操作
	1、pwdmg = urllib.request.HTTPPassword...()
	2、pwdmg.add_password(
	   None,{"http":"IP:端口"},"user","pwd")
      2、Handler开始
*******************************************
Day04笔记
1、xpath工具(解析)
  1、xpath
    在XML文档中查找信息的语言,同样适用于HTML文档检索
  2、xpath辅助工具
    1、Chrome插件 ：Xpath Helper
      1、打开/关闭 ：Ctrl + Shift + x
    2、Firefox插件 ：Xpath checker
    3、Xpath表达式编辑工具 ：XML Quire
  3、Xpath匹配规则
    1、匹配演示 
      1、匹配bookstore下所有节点 ：/bookstore
      2、查找所有的book节点 ：//book
      3、查找/bookstore下的book节点 ：/bookstore/book
      4、查找所有book节点下的title节点中,lang属性值为 "en" 的节点 ： //book/title[@lang="en"]
      5、查找bookstore下的第2个book节点下的title节点
        /bookstore/book[2]/title/text()
    2、选取节点
      / ：从根节点开始选取
      //：从整个文档中查找节点
          //price、/bookstore/book//price
      @ ：选取某个节点
          //div[@class="movie-info"]/a[@class="name"]
      @ ：获取某个节点的属性值
	  获取所有book下的title节点的lang属性值
	  //book/title/@lang
          <a src="http://kdjfladjl.jpg">
    3、匹配多路径
      1、符号 ： |
      2、获取所有book节点下的title节点和price节点
        //book/title | //book/price
    5、函数
      1、contains()
        匹配1个属性值中包含某个字符串的节点
	所有的title节点中lang属性值包含"ch"的节点
	//title[contains(@lang,"ch")]
      2、text()
        //title[contains(@lang,"ch")]/text()
2、lxml库及xpath使用
  1、lxml库 ：HTML/XML解析库
    1、Anaconda ：conda install lxml
    2、Windows cmd：python -m pip install lxml
    3、Ubuntu   ：sudo pip3 install lxml
  2、使用流程
    1、导入模块 ：from lxml import etree
    2、创建解析对象 ：parseHtml = etree.HTML(html)
    3、调用xpath
      r_list = parseHtml.xpath('xpath表达式')
    4、如何获取节点对象的文本内容
      节点对象名.text
3、抓取百度贴吧中所有帖子里的图片
  见 ：02_百度贴吧图片抓取.py
  1、目标 ：指定贴吧的所有图片
  2、思路
    1、获取贴吧主页URL,下一页：找URL规律
    2、获取1页中每个帖子的URL 
      ['帖子链接1','','','']
    3、For循环遍历2中列表,发请求,提取帖子中图片链接
      ["图片链接1","图片链接2","","",""]
    4、For循环遍历3中列表,发请求,以wb方式保存本地
  3、步骤
    1、获取贴吧主页URL 
      http://tieba.baidu.com/f? + 查询参数
    2、(xpath)提取页面中所有帖子的URL
      src : 完整链接
      href : 需要和主URL进行拼接
      http://tieba.baidu.com + /p/5960551987
      '//div[@class="t_con cleafix"]/div/div/div/a/@href'
    3、匹配1个帖子中所有图片的URL
      '//div[@class="d_post_content j_d_post_content  clearfix"]/img/@src'
4、抓取百度贴吧中帖子里的视频和图片
  见 ：04_百度贴吧视频和图片抓取.py
  1、视频xpath表达式
    //div[@class="video_src_wrapper"]/div/video/@src
5、注意
  1、xpath表达式在网页中可匹配但在程序中是空列表
    1、User-Agent ：最好换为IE浏览器
    2、把页面下载下来,再分析
6、案例 ：糗事百科-xpath
  1、目标 ：用户昵称、段子内容、好笑数量、评论数量
  2、步骤
    1、找URL
      https://www.qiushibaike.com/8hr/page/1/
    2、xpath表达式
      1、基准的xpath表达式(每个段子的节点对象)
	 //div[contains(@id,"qiushi_tag_")]
      2、for element in [段子节点对象列表]:
           用户昵称 ：'./div/a/h2'
	   段子内容 ：'.//div[@class="content"]/span'
	   好笑数量 ：'.//i'
	   评论数量 ：'.//i'
    3、写代码
      1、












